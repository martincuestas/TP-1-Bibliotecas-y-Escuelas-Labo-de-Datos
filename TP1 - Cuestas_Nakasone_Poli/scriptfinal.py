# -*- coding: utf-8 -*-
"""ScriptFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mKZFRaaEBmLly1ags4aI5fZ3VGj8xeX5
"""

# -*- coding: utf-8 -*-
"""
Trabajo Práctico 1: escuelas y bibliotecas
Laboratorio de Datos (DC) - Comisión Laje
Estudiantes:
    Cuestas Martín
    Nakasone Julián
    Poli Dante

Código asociado a los distintos procesos relatados en el informe.
Todo es reproducible.

Contenidos:
    1- Importación de librerias
    2- GQM
    3- Limpieza de datos y armado de datasets asociados al modelo relacional
    4- Revisión de claves foráneas
    5- Consultas SQL
    6- Visualización de datos

Referencias:
    - dataframe##_ini: dataset original
    - dataframe##: dataset preprocesado

IMPORTANTE ACLARACIÓN: SE DEBE EJECUTAR EL CÓDIGO DESDE LA CARPETA QUE ENVÍAMOS.
EL CÓDIGO GENERA LAS TABLAS RELACIONADAS AL MODELO RELACIONAL POR FUERA DE LA
CARPETA DE "TablasModelo", YA QUE NO SE QUIERE PERTURBAR LA CARPETA ORIGINAL Y
DE PASO, SE QUIERE DEMOSTRAR QUE EL CÓDIGO EFECTIVAMENTE GENERA DICHAS TABLAS.


"""

#-------------------------------------------------------------------------
# Importación de librerias
#-------------------------------------------------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import subprocess
import sys
try:
    import seaborn
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "seaborn"])
    import seaborn  # Intentamos importar nuevamente tras la instalación
subprocess.check_call([sys.executable, "-m", "pip", "install", "duckdb"])
import duckdb
import seaborn as sns
import re



#-------------------------------------------------------------------------
# GQM
#-------------------------------------------------------------------------

carpeta = "TablasOriginales/"

# Bibliotecas Populares completitud
bibliotecas_populares = pd.read_csv(carpeta+"bibliotecas-populares.csv")
metrica_completitud_mail = bibliotecas_populares["mail"].isnull().sum() / len(bibliotecas_populares)
metrica_completitud_cod_tel = bibliotecas_populares["cod_tel"].isnull().sum() / len(bibliotecas_populares)
metrica_completitud_telefono = bibliotecas_populares["cod_tel"].isnull().sum() / len(bibliotecas_populares)
metrica_completitud_web = bibliotecas_populares["web"].isnull().sum() / len(bibliotecas_populares)
metrica_completitud_piso = bibliotecas_populares["piso"].isnull().sum() / len(bibliotecas_populares)
metrica_completitud_informacion_adicional = bibliotecas_populares["informacion_adicional"].isnull().sum() / len(bibliotecas_populares)

print('Metrica de completitud de mail:', metrica_completitud_mail*100,'%')
print('Metrica de completitud de cod_tel:',metrica_completitud_cod_tel*100,'%')
print('Metrica de completitud de telefono:',metrica_completitud_telefono*100,'%')
print('Metrica de completitud de web:',metrica_completitud_web*100,'%')
print('Metrica de completitud de piso:',metrica_completitud_piso*100,'%')
print('Metrica de completitud de informacion_adicional:',metrica_completitud_informacion_adicional*100,'%')

# Bibliotecas Populares consistencia

metrica_cantidad_chascomus_id = (bibliotecas_populares["id_departamento"] == 6217).sum()
print('Cantidad de registros con chascomus_id:', metrica_cantidad_chascomus_id)

# Establecimientos Educativos completitud

Establecimientos_Educativos = pd.read_excel(carpeta+"2022_padron_oficial_establecimientos_educativos.xlsx", skiprows = 6)

Establecimientos_Educativos = Establecimientos_Educativos.replace(r'^\s*$', pd.NA, regex=True)

metrica_completitud_Domicilio = Establecimientos_Educativos["Domicilio"].isnull().sum() / len(Establecimientos_Educativos)
print(Establecimientos_Educativos["Domicilio"].isnull().sum())
metrica_completitud_CP = Establecimientos_Educativos["C. P."].isnull().sum() / len(Establecimientos_Educativos)
print(Establecimientos_Educativos["C. P."].isnull().sum())
metrica_completitud_Telefono = Establecimientos_Educativos["Teléfono"].isnull().sum() / len(Establecimientos_Educativos)
print(Establecimientos_Educativos["Teléfono"].isnull().sum())
metrica_completitud_CodigoArea = Establecimientos_Educativos["Código de área"].isnull().sum() / len(Establecimientos_Educativos)
metrica_completitud_Mail = Establecimientos_Educativos["Mail"].isnull().sum() / len(Establecimientos_Educativos)

print('Metrica de completitud de Domicilio:', metrica_completitud_Domicilio*100,'%')
print('Metrica de completitud de C.P.:',metrica_completitud_CP*100,'%')
print('Metrica de completitud de Teléfono:',metrica_completitud_Telefono*100,'%')
print('Metrica de completitud de Código de Área:',metrica_completitud_CodigoArea*100,'%')
print('Metrica de completitud de Mail:',metrica_completitud_Mail*100,'%')

# Establecimientos Educativos consistencia


telefono_regex = re.compile(r'^(\+?\d{1,3}[\s.-]?)?(\(?\d{1,4}\)?[\s.-]?)?[\d\s.-]{6,}$')

# Función para validar cada entrada
def es_telefono_valido(valor):
    if pd.isna(valor):
        return False
    # Dividir por '/' si hay múltiples números
    numeros = str(valor).split('/')
    for numero in numeros:
        numero = numero.strip()
        if not telefono_regex.match(numero):
            return False
    return True

Establecimientos_Educativos['Teléfono_valido'] = Establecimientos_Educativos['Teléfono'].apply(es_telefono_valido)

inconsistencias = (~Establecimientos_Educativos['Teléfono_valido']).sum()
total_instancias = len(Establecimientos_Educativos)
print(f"Número de inconsistencias en la columna 'Teléfono': {inconsistencias}")
print(f"Porcentaje de inconsistencia: {inconsistencias/total_instancias*100}%")




#-------------------------------------------------------------------------
# Limpieza de datos y armado de datasets asociados al modelo relacional
#-------------------------------------------------------------------------


establecimientos_educativos = pd.read_excel(carpeta+'2022_padron_oficial_establecimientos_educativos.xlsx')
establecimientos_educativos.to_csv("establecimientos_educativos.csv", index=False, encoding='utf-8')


padron_poblacion = pd.read_excel(carpeta+'padron_poblacion.xlsX')
padron_poblacion.to_csv("padron_poblacion.csv", index=False, encoding='utf-8')



dataframeBP_ini = duckdb.sql(f"""
    SELECT * FROM read_csv_auto('{carpeta}bibliotecas-populares.csv')
""").df()

dataframeEE_ini = duckdb.sql(f"""
    SELECT * FROM read_csv_auto('establecimientos_educativos.csv')
""").df()

dataframePP_ini = duckdb.sql(f"""
    SELECT * FROM read_csv_auto('padron_poblacion.csv')
""").df()


# Preprocesado de tabla original de Padrón Población

dataframePP = dataframePP_ini.copy()
dataframePP = dataframePP.drop(['CEPAL/CELADE Redatam+SP 01/30/2025'], axis=1) # Elimino la columna vacía, 'axis' indica que me refiero a columnas
dataframePP = dataframePP.dropna(how='all') # Elimino todas las filas que tengan todos valores NULL
dataframePP = dataframePP[dataframePP['Unnamed: 1'] != 'Edad'] # Elimino todas las filas que deberían ser los nombres de las columnas
dataframePP.reset_index(inplace=True,drop=True) # Reseteo los indices del dataframe xq faltaban los indices que fueron eliminados previamente



# DATASET Población_Depto

data: list[list] = [] # Armo la lista de data donde voy a contener todas las filas en forma de listas. Pensarlo como una matriz
for i in range(0,55003): # Indexo hasta la longitud del dataframe que necesito
    # Si el código de área es de CABA...
    if('AREA # 02' in dataframePP.iloc[i,0]):
        instancia: list = []
        # Guardo el valor del area, dividiendo los dos úlitmos dígitos (como número entero) por 7
        if(int(dataframePP.iloc[i,0][9:12])//7 < 10):
            area = '0200' + str(int(dataframePP.iloc[i,0][9:12])//7)
        else:
            area = '020' + str(int(dataframePP.iloc[i,0][9:12])//7)
        instancia.append(area)
    # Corregimos las excepciones...
    elif('AREA # 94' in dataframePP.iloc[i,0]):
        instancia: list = []
        if(dataframePP.iloc[i,1] == 'Río Grande'):
            area = '94007'
        elif(dataframePP.iloc[i,1] == 'Tolhuin'):
            area = '94011'
        elif(dataframePP.iloc[i,1] == 'Ushuaia'):
            area = '94014'
        instancia.append(area)
    # Cuando el código de área y el id de departamento coinciden...
    elif('AREA' in dataframePP.iloc[i,0]):
        instancia: list = []
        area = dataframePP.iloc[i,0][7:12]
        instancia.append(area)
    # Agregamos los grupos etarios a las instancias...
    elif(dataframePP.iloc[i,0] == '0'):
        instancia.append('Entre 0 y 5 anios')
        # Sumamos las poblaciones de todas las edades de este grupo, entonces necesitamos analizarlos como enteros
        instancia.append(str(int(dataframePP.iloc[i,1].replace(" ","")) + int(dataframePP.iloc[i+1,1].replace(" ","")) + int(dataframePP.iloc[i+2,1].replace(" ",""))
                             + int(dataframePP.iloc[i+3,1].replace(" ","")) + int(dataframePP.iloc[i+4,1].replace(" ","")) + int(dataframePP.iloc[i+5,1].replace(" ",""))))
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos el grupo etario de la instancia porque necesitamos armar una instancia por grupo etario del mismo depto
        instancia = instancia[0:1]
    elif(dataframePP.iloc[i,0] == '6'):
        instancia.append('Entre 6 y 11 anios')
        # Sumamos las poblaciones de todas las edades de este grupo, entonces necesitamos analizarlos como enteros
        instancia.append(str(int(dataframePP.iloc[i,1].replace(" ","")) + int(dataframePP.iloc[i+1,1].replace(" ","")) + int(dataframePP.iloc[i+2,1].replace(" ",""))
                             + int(dataframePP.iloc[i+3,1].replace(" ","")) + int(dataframePP.iloc[i+4,1].replace(" ","")) + int(dataframePP.iloc[i+5,1].replace(" ",""))))
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos el grupo etario de la instancia porque necesitamos armar una instancia por grupo etario del mismo depto
        instancia = instancia[0:1]
    elif(dataframePP.iloc[i,0] == '12'):
        instancia.append('Entre 12 y 18 anios')
        # Sumamos las poblaciones de todas las edades de este grupo, entonces necesitamos analizarlos como enteros
        instancia.append(str(int(dataframePP.iloc[i,1].replace(" ","")) + int(dataframePP.iloc[i+1,1].replace(" ","")) + int(dataframePP.iloc[i+2,1].replace(" ",""))
                             + int(dataframePP.iloc[i+3,1].replace(" ","")) + int(dataframePP.iloc[i+4,1].replace(" ","")) + int(dataframePP.iloc[i+5,1].replace(" ",""))))
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos el grupo etario de la instancia porque necesitamos armar una instancia por grupo etario del mismo depto
        instancia = instancia[0:1]
    elif(dataframePP.iloc[i,0] == '19'):
        instancia.append('Mayores de 19 anios')
        suma: int = 0
        j = i
        while (dataframePP.iloc[j,0] != 'Total'):
            suma += int(dataframePP.iloc[j,1].replace(" ","")) # Sumamos las poblaciones de todas las edades de este grupo
            j += 1
        instancia.append(suma)
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos el grupo etario de la instancia porque necesitamos armar una instancia por grupo etario del mismo depto
        instancia = instancia[0:1]
Poblacion_Depto = pd.DataFrame(data, columns=['id_departamento','Rango_Etario','cantidad']) # Creo un nuevo dataframe con 'data' y nombro las columnas
#Poblacion_Depto.to_csv('Poblacion_Depto.csv', index=False) # Exporto el dataset a .csv
print("Tabla Poblacion_Depto:")
print(Poblacion_Depto)



# Preprocesado de tabla original de Establecimientos Educativos

dataframeEE = dataframeEE_ini.copy()
dataframeEE = dataframeEE.drop([0,1,2,3,4]) # Elimino filas irrelevantes
dataframeEE = dataframeEE[dataframeEE['Unnamed: 13'] == '1'] # Elimino todas las instancias que no poseen modalidad común
dataframeEE = dataframeEE[['Unnamed: 1','Unnamed: 2','Unnamed: 9','Unnamed: 20','Unnamed: 21','Unnamed: 22','Unnamed: 23','Unnamed: 24','Unnamed: 25','Unnamed: 26']] # Nos quedamos con las columnas que nos interesan
dataframeEE.reset_index(inplace=True,drop=True) # Reseteo los indices del dataframe xq faltaban los indices que fueron eliminados previamente



# DATASET Escuela

data: list[list] = [] # Armo la lista de data donde voy a contener todas las filas en forma de listas. Pensarlo como una matriz
for i in range(0,50277): # Indexo hasta la longitud del dataframe
    # Creamos una nueva instancia
    instancia: list = []
    # Agregamos el cuanexo y el nombre del establecimiento educativo
    instancia.append(dataframeEE.iloc[i,0])
    instancia.append(dataframeEE.iloc[i,1])
    # Solucionamos la excepción de los códigos de CABA
    if(dataframeEE.iloc[i,2][0:2] == '02'):
        instancia.append(dataframeEE.iloc[i,2][0:2] + '0' + dataframeEE.iloc[i,2][3:5]) # Selecciono la parte del id_departamento
    else:
        instancia.append(dataframeEE.iloc[i,2][0:5])
    data.append(instancia) # Agregamos las instancias a data
Escuela = pd.DataFrame(data, columns=['Cuanexo','Nombre','id_departamento'])
#Escuela.to_csv('Escuela.csv', index=False) # Exporto el dataset a .csv
print("Tabla Escuela:")
print(Escuela)


# DATASET Escuela_Submodalidad

data: list[list] = [] # Armo la lista de data donde voy a contener todas las filas en forma de listas. Pensarlo como una matriz
for i in range(0,50277): # Indexo hasta la longitud del dataframe
    # Creamos una nueva instancia
    instancia: list = []
    # Agrego el cuanexo a la instancia
    instancia.append(dataframeEE.iloc[i,0])
    # Agrupamos las submodalidades y agregamos una instancia por cada submodalidad que posee
    if(dataframeEE.iloc[i,3] == '1' or dataframeEE.iloc[i,4] == '1'):
        modalidad = 'Nivel inicial'
        instancia.append(modalidad)
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos la submodalidad de la instancia porque necesitamos armar una instancia por submodalidad de la misma escuela
        instancia = instancia[0:1]
    if(dataframeEE.iloc[i,5] == '1'):
        modalidad = 'Primaria'
        instancia.append(modalidad)
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos la submodalidad de la instancia porque necesitamos armar una instancia por submodalidad de la misma escuela
        instancia = instancia[0:1]
    if(dataframeEE.iloc[i,6] == '1' or dataframeEE.iloc[i,7] == '1'):
        modalidad = 'Secundaria'
        instancia.append(modalidad)
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos la submodalidad de la instancia porque necesitamos armar una instancia por submodalidad de la misma escuela
        instancia = instancia[0:1]
    if(dataframeEE.iloc[i,8] == '1' or dataframeEE.iloc[i,9] == '1'):
        modalidad = 'No Universitario'
        instancia.append(modalidad)
        data.append(instancia) # Agregamos las instancias a data
        # Eliminamos la submodalidad de la instancia porque necesitamos armar una instancia por submodalidad de la misma escuela
        instancia = instancia[0:1]
Escuela_Submodalidad = pd.DataFrame(data, columns=['Cuanexo','Submodalidad'])
#Escuela_Submodalidad.to_csv('Escuela_Submodalidad.csv', index=False) # Exporto el dataset a .csv
print("Tabla Escuela_Submodalidad:")
print(Escuela_Submodalidad)



# Preprocesado de tabla original de Bibliotecas Populares

dataframeBP = dataframeBP_ini.copy()
dataframeBP = dataframeBP[['id_departamento','nombre','mail','fecha_fundacion','nro_conabip']]


# DATASET Biblioteca_Popular

for i in range(0,1902):
    # Queremos quedarnos con la fecha como string
    dataframeBP.iloc[i,3] = str(dataframeBP.iloc[i,3])[0:4]
    # Actualizamos el dato desactualizado
    if(dataframeBP.iloc[i,0][0:5] == '06217'):
        dataframeBP.iloc[i,0] = '06218'
#dataframeBP.to_csv('Biblioteca_Popular.csv', index=False) # Exporto el dataset a .csv
print("Tabla Biblioteca_Popular:")
print(dataframeBP)


# DATASET Departamento

Departamento = dataframeEE_ini.copy()
Departamento = Departamento.drop([0,1,2,3,4,5]) # Elimino todas las filas que son irrelevantes
Departamento = Departamento[['Unnamed: 9','Unnamed: 11']] # Me quedo solo con los id_departamento y nombres de departamento
Departamento.reset_index(inplace=True,drop=True) # Reseteo los indices del dataframe xq faltaban los indices que fueron eliminados previamente

data: list[list] = [] # Armo la lista de data donde voy a contener todas las filas en forma de listas. Pensarlo como una matriz
for i in range(0,63662): # Indexo hasta la longitud del dataframe
    # Creamos una nueva instancia
    instancia: list = []
    # Solucionamos la excepción de CABA
    if(Departamento.iloc[i,0][0:2] == '02'):
        id_depto = Departamento.iloc[i,0][0:2] + '0' + Departamento.iloc[i,0][3:5] # Modifico el tercer dígito por un cero
        nombre_depto = Departamento.iloc[i,1]
    else: # Agregamos el resto de id's y nombres
        id_depto = Departamento.iloc[i,0][0:5]
        nombre_depto = Departamento.iloc[i,1]
    instancia.append(id_depto)
    # Agregamos el id_provincia a la instancia
    instancia.append(Departamento.iloc[i,0][0:2])
    instancia.append(nombre_depto)
    data.append(instancia) # Agregamos las instancias a data
data.append(['02000','02','CABA (total)'])
Departamento = pd.DataFrame(data, columns=['id_departamento','id_provincia','nombre'])
Departamento = Departamento.drop_duplicates() # Solo quiero una instancia por departamento
Departamento.reset_index(inplace=True,drop=True) # Reseteo los indices del dataframe xq faltaban los indices que fueron eliminados previamente
#Departamento.to_csv('Departamento.csv', index=False) # Exporto el dataset a .csv
print("Tabla Departamento:")
print(Departamento)


# DATASET Provincia

Provincia = dataframeEE_ini.copy()
Provincia = Provincia.drop([0,1,2,3,4,5]) # Elimino filas irrelevantes
Provincia = Provincia[['Unnamed: 9','Unnamed: 0']] # Solo nos quedamos con id_departamento y los nombres de provincia
Provincia.reset_index(inplace=True,drop=True) # Reseteo los indices del dataframe xq faltaban los indices que fueron eliminados previamente

data: list[list] = [] # Armo la lista de data donde voy a contener todas las filas en forma de listas. Pensarlo como una matriz
for i in range(0,63662): # Indexo hasta la longitud del dataframe
    # Creamos una nueva instancia
    instancia: list = []
    # Agregamos los id_provincia y los nombres de las provincias
    instancia.append(Provincia.iloc[i,0][0:2])
    instancia.append(Provincia.iloc[i,1])
    data.append(instancia) # Agregamos las instancias a data
Provincia = pd.DataFrame(data, columns=['id_provincia','nombre'])
Provincia = Provincia.drop_duplicates()
Provincia.reset_index(inplace=True,drop=True) # Reseteo los indices del dataframe xq faltaban los indices que fueron eliminados previamente
#Provincia.to_csv('Provincia.csv', index=False) # Exporto el dataset a .csv
print("Tabla Provincia:")
print(Provincia)


#-------------------------------------------------------------------------
# Revisión de claves foráneas
#-------------------------------------------------------------------------

# Registramos todos los id_departamento que tiene cada tabla relacionada al MR

data_deptos_PP = duckdb.sql("""
                     SELECT DISTINCT id_departamento
                     FROM 'TablasModelo/Poblacion_Depto.csv';
                     """).df()

data_deptos_EE = duckdb.sql("""
                     SELECT DISTINCT id_departamento
                     FROM 'TablasModelo/Escuela.csv';
                     """).df()

data_deptos_BP = duckdb.sql("""
                     SELECT DISTINCT id_departamento
                     FROM 'TablasModelo/Biblioteca_Popular.csv';
                     """).df()

# Probamos que la tabla que contiene los departamentos efectivamente contenga a todos los departamentos de las tablas

data_resta_EE_Depto = duckdb.sql("""
                               SELECT DISTINCT id_departamento
                               FROM 'TablasModelo/Escuela.csv'
                               EXCEPT
                               SELECT DISTINCT id_departamento
                               FROM 'TablasModelo/Departamento.csv';
                               """).df()

data_resta_BP_Depto = duckdb.sql("""
                               SELECT DISTINCT id_departamento
                               FROM 'TablasModelo/Biblioteca_Popular.csv'
                               EXCEPT
                               SELECT DISTINCT id_departamento
                               FROM 'TablasModelo/Departamento.csv';
                               """).df()

data_resta_PP_Depto = duckdb.sql("""
                               SELECT DISTINCT id_departamento
                               FROM 'TablasModelo/Poblacion_Depto.csv'
                               EXCEPT
                               SELECT DISTINCT id_departamento
                               FROM 'TablasModelo/Departamento.csv';
                               """).df()

data_resta_Depto_Prov = duckdb.sql("""
                             SELECT DISTINCT id_provincia
                             FROM 'TablasModelo/Departamento.csv'
                             EXCEPT
                             SELECT DISTINCT id_provincia
                             FROM 'TablasModelo/Provincia.csv';
                             """).df()



#-------------------------------------------------------------------------
# Consultas SQL
#-------------------------------------------------------------------------

carpeta = "TablasModelo/"

df_Biblioteca_Popular = pd.read_csv(carpeta+"Biblioteca_Popular.csv")
df_Escuela = pd.read_csv(carpeta+"Escuela.csv")
df_Escuela_Submodalidad = pd.read_csv(carpeta+"Escuela_Submodalidad.csv")
df_Poblacion_Depto = pd.read_csv(carpeta+"Poblacion_Depto.csv")
df_Departamento = pd.read_csv(carpeta+"Departamento.csv")
df_Provincia = pd.read_csv(carpeta+"Provincia.csv")


departamentos = duckdb.sql("""
                        SELECT df_Provincia.id_provincia, df_Provincia.nombre AS Provincia, df_Departamento.id_departamento, df_Departamento.nombre AS Departamento
                        FROM df_Provincia
                        INNER JOIN df_Departamento
                        ON df_Provincia.id_provincia == df_Departamento.id_provincia
                        """).df()
##Consulta 1
conteo_ee = duckdb.sql("""
    SELECT
        ee.id_departamento,
        COUNT(*) FILTER (WHERE es.Submodalidad = 'Nivel inicial') AS Jardines,
        COUNT(*) FILTER (WHERE es.Submodalidad = 'Primaria') AS Primarias,
        COUNT(*) FILTER (WHERE es.Submodalidad = 'Secundaria') AS Secundarias
    FROM df_Escuela AS ee
    INNER JOIN df_Escuela_Submodalidad AS es
    ON ee.Cuanexo = es.Cuanexo
    GROUP BY ee.id_departamento
""").df()

poblacion_transformada = duckdb.sql("""
    SELECT
        df_Departamento.id_departamento,
        SUM(CASE WHEN Rango_Etario = 'Entre 0 y 5 anios' THEN CAST(cantidad AS INTEGER) ELSE NULL END) AS Poblacion_Jardin,
        SUM(CASE WHEN Rango_Etario = 'Entre 6 y 11 anios' THEN CAST(cantidad AS INTEGER) ELSE NULL END) AS Poblacion_Primario,
        SUM(CASE WHEN Rango_Etario = 'Entre 12 y 18 anios' THEN CAST(cantidad AS INTEGER) ELSE NULL END) AS Poblacion_Secundario
    FROM df_Departamento
    LEFT OUTER JOIN df_Poblacion_Depto
    ON df_Departamento.id_departamento == df_Poblacion_Depto.id_departamento
    WHERE df_Departamento.id_departamento != '2000'
    GROUP BY df_Departamento.id_departamento
    ORDER BY df_Departamento.id_departamento DESC
    """).df()


consulta1 = duckdb.sql("""
    SELECT
        d.Provincia,
        d.Departamento,
        ee.Jardines,
        pob.Poblacion_Jardin,
        ee.Primarias,
        pob.Poblacion_Primario,
        ee.Secundarias,
        pob.Poblacion_Secundario
    FROM departamentos AS d
    INNER JOIN poblacion_transformada AS pob
    ON pob.id_departamento = d.id_departamento
    LEFT OUTER JOIN conteo_ee AS ee
    ON ee.id_departamento = d.id_departamento
    ORDER BY d.Provincia ASC, ee.Primarias DESC
""").df()
print("Consulta 1:")
print(consulta1)

##Consulta 2
bibliotecas_desde_1950 = duckdb.sql("""
                        SELECT df_Biblioteca_Popular.id_departamento, COUNT(*) AS Cantidad_De_BP_Fundadas_Desde_1950
                        FROM df_Biblioteca_Popular
                        WHERE CAST(SUBSTR(fecha_fundacion, 1, 4) AS INTEGER) > 1949
                        GROUP BY df_Biblioteca_Popular.id_departamento
                        ORDER BY Cantidad_De_BP_Fundadas_Desde_1950 DESC
                        """).df()

consulta2 = duckdb.sql("""
                        SELECT departamentos.Provincia, departamentos.Departamento, bibliotecas_desde_1950.Cantidad_De_BP_Fundadas_Desde_1950
                        FROM departamentos
                        LEFT OUTER JOIN bibliotecas_desde_1950
                        ON bibliotecas_desde_1950.id_departamento == departamentos.id_departamento
                        GROUP BY departamentos.Provincia, departamentos.Departamento, bibliotecas_desde_1950.Cantidad_De_BP_Fundadas_Desde_1950
                        ORDER BY Provincia ASC, Cantidad_De_BP_Fundadas_Desde_1950 DESC
                        """).df()
print("Consulta 2:")
print(consulta2)

##Consulta3
escuelas =  duckdb.sql("""
                        SELECT departamentos.id_provincia, departamentos.id_departamento, COUNT(*) AS Cant_EE
                        FROM departamentos
                        LEFT OUTER JOIN df_Escuela
                        ON departamentos.id_departamento == df_Escuela.id_departamento
                        GROUP BY departamentos.id_provincia, departamentos.id_departamento
                        ORDER BY Cant_EE DESC
                        """).df()

bibliotecas =  duckdb.sql("""
                        SELECT df_Biblioteca_Popular.id_departamento, COUNT(*) AS Cant_BP
                        FROM df_Biblioteca_Popular
                        LEFT OUTER JOIN departamentos
                        ON departamentos.id_departamento == df_Biblioteca_Popular.id_departamento
                        GROUP BY df_Biblioteca_Popular.id_departamento
                        ORDER BY Cant_BP DESC
                        """).df()

poblacion =  duckdb.sql("""
                        SELECT departamentos.id_provincia, departamentos.id_departamento, SUM(df_Poblacion_Depto.cantidad) AS Población
                        FROM departamentos, df_Poblacion_Depto

                        WHERE df_Poblacion_Depto.id_departamento == departamentos.id_departamento
                        GROUP BY departamentos.id_provincia, departamentos.id_departamento

                        """).df()


pre_consulta3 = duckdb.sql("""
                        SELECT departamentos.Provincia, departamentos.Departamento, escuelas.Cant_EE, bibliotecas.Cant_BP, poblacion.Población
                        FROM departamentos
                        LEFT OUTER JOIN escuelas
                        ON departamentos.id_departamento == escuelas.id_departamento
                        LEFT OUTER JOIN bibliotecas
                        ON departamentos.id_departamento == bibliotecas.id_departamento
                        LEFT OUTER JOIN poblacion
                        ON departamentos.id_departamento == poblacion.id_departamento
                        WHERE departamentos.id_departamento != '2000'
                        ORDER BY Cant_EE DESC, Cant_BP DESC
                        """).df()

total_caba = duckdb.sql("""
                        SELECT departamentos.id_departamento, departamentos.Provincia, departamentos.Departamento, SUM(Cant_EE) AS Cant_EE, SUM(Población) AS Población
                        FROM departamentos

                        INNER JOIN pre_consulta3
                        ON departamentos.Provincia == pre_consulta3.Provincia
                        WHERE departamentos.id_departamento == '2000'
                        GROUP BY departamentos.id_departamento, departamentos.Provincia, departamentos.Departamento
                        """).df()

bibliotecas_caba = duckdb.sql("""
                        SELECT id_departamento, COUNT(*) AS Cant_BP
                        FROM df_Biblioteca_Popular
                        WHERE id_departamento == 2000
                        GROUP BY id_departamento
                        """).df()

data_total_caba = duckdb.sql("""
                        SELECT total_caba.Provincia, total_caba.Departamento, total_caba.Cant_EE, bibliotecas_caba.Cant_BP, total_caba.Población
                        FROM total_caba
                        INNER JOIN bibliotecas_caba
                        ON total_caba.id_departamento == bibliotecas_caba.id_departamento
                        """).df()

consulta3 = duckdb.sql("""
                        SELECT Provincia, Departamento, Cant_EE, Cant_BP, Población
                        FROM pre_consulta3
                        UNION
                        SELECT Provincia, Departamento, Cant_EE, Cant_BP, Población
                        FROM data_total_caba
                        ORDER BY Cant_EE DESC, Cant_BP DESC, Provincia ASC, Departamento ASC
                        """).df()
print("Consulta 3:")
print(consulta3)

##Consulta 4

dominio_mas_usado = duckdb.sql("""
    SELECT id_departamento, dominio, cantidad
    FROM (
        SELECT
            id_departamento,
            SPLIT_PART(LOWER(mail), '@', 2) AS dominio,
            COUNT(*) AS cantidad,
            ROW_NUMBER() OVER (PARTITION BY id_departamento ORDER BY COUNT(*) DESC) AS rn
        FROM df_Biblioteca_Popular
        WHERE mail IS NOT NULL AND mail LIKE '%@%'
        GROUP BY id_departamento, dominio
    )
    WHERE rn = 1
    ORDER BY id_departamento ASC
""").df()

porcentaje_mails = duckdb.sql("""
    SELECT
        id_departamento,
        ROUND(100.0 * COUNT(mail) / COUNT(*), 2) AS porcentaje_mail_no_nulo
    FROM df_Biblioteca_Popular
    GROUP BY id_departamento
    ORDER BY id_departamento
""").df()

## Añadimos como columnas extra:
## .el dato de la cantidad de bibliotecas en cada departamento
## .el porcentaje de BP que tienen mail en cada departamento

consulta4 = duckdb.sql("""
    SELECT
        d.Provincia,
        d.Departamento,
        dm.dominio AS Dominio_Mas_Frecuente,
        pm.porcentaje_mail_no_nulo AS Porcentaje_BP_con_Mail
    FROM departamentos AS d
    LEFT JOIN dominio_mas_usado AS dm
        ON d.id_departamento = dm.id_departamento
    LEFT JOIN porcentaje_mails AS pm
        ON d.id_departamento = pm.id_departamento
    ORDER BY d.Provincia, d.Departamento
""").df()
print("Consulta 4:")
print(consulta4)


#-------------------------------------------------------------------------
# Visualización de datos
#-------------------------------------------------------------------------

##Visualización 1, se usa la consulta 3.

BP_por_Provincia = duckdb.sql("""
    SELECT consulta3.Provincia, SUM(consulta3.Cant_BP) AS Cant_BP
    FROM consulta3
    GROUP BY consulta3.Provincia
    ORDER BY Cant_BP DESC
""").df()

fig, ax = plt.subplots(figsize=(15, 6))

bars = ax.bar(BP_por_Provincia['Provincia'], BP_por_Provincia['Cant_BP'], color='skyblue', width=0.8)
ax.set_xlabel('Provincia')
ax.set_ylabel('Cantidad de Bibliotecas Populares')
ax.set_title('Cantidad de Bibliotecas Populares por Provincia')
ax.bar_label(bars, fontsize = 9)
ax.set_xticklabels(BP_por_Provincia['Provincia'], rotation=45, ha='right', fontsize=10)
plt.show()


BP_por_Provincia = duckdb.sql("""
    SELECT consulta3.Provincia, SUM(consulta3.Cant_EE) AS Cant_EE
    FROM consulta3
    GROUP BY consulta3.Provincia
    ORDER BY Cant_EE DESC
""").df()


# EXTRA

poblacion_provincia = duckdb.sql("""
    SELECT consulta3.Provincia, SUM(consulta3.Población) AS Población
    FROM consulta3
    GROUP BY consulta3.Provincia
    ORDER BY Población DESC
""").df()

fig, ax = plt.subplots(figsize=(15, 6))

bars = ax.bar(poblacion_provincia['Provincia'], poblacion_provincia['Población'], color='orange', width=0.8)
ax.set_xlabel('Provincia')
ax.set_ylabel('Población')
ax.set_title('Población por Provincia')
ax.set_xticklabels(poblacion_provincia['Provincia'], rotation=45, ha='right', fontsize=10)
plt.show()

fig, ax = plt.subplots(figsize=(15, 6))

bars = ax.bar(BP_por_Provincia['Provincia'], BP_por_Provincia['Cant_EE'], color='green', width=0.8)
ax.set_xlabel('Provincia')
ax.set_ylabel('Cantidad de Establecimientos Educativos')
ax.set_title('Cantidad de Establecimientos Educativos por Provincia')
ax.bar_label(bars, fontsize = 9)
ax.set_xticklabels(BP_por_Provincia['Provincia'], rotation=45, ha='right', fontsize=10)
plt.show()


color_daltonico_friendly = sns.color_palette("colorblind")
plt.figure(figsize=(10,6))

plt.scatter(consulta1['Jardines'], consulta1['Poblacion_Jardin'], color = color_daltonico_friendly[0],  label = 'Jardines', s = 10, alpha = 0.7)
plt.scatter(consulta1['Primarias'], consulta1['Poblacion_Primario'], color = color_daltonico_friendly[1], label = 'Primaria', s = 10, alpha = 0.7)
plt.scatter(consulta1['Secundarias'], consulta1['Poblacion_Secundario'], color = color_daltonico_friendly[2], label = 'Secundarias', s = 10, alpha = 0.7)

plt.xlabel('Cantidad de Establecimientos Educativos')
plt.ylabel('Población por grupo etario')
plt.title('Cantidad de Establecimientos Educativos vs Población')
plt.legend()
plt.grid(True)
plt.show()



# EXTRA

plt.figure(figsize=(10, 6))

plt.scatter(
    consulta3['Cant_BP'],
    consulta3['Población'],
    color=color_daltonico_friendly[4],
    s=20,
    alpha=0.7
)

plt.xlabel('Cantidad de Bibliotecas Populares')
plt.ylabel('Población por Departamento')
plt.title('Relación entre Población y Cantidad de Bibliotecas Populares por Departamento')
plt.grid(True)

plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))

plt.show()

#cant_escuelas_vs_blibliotecas_porDepto
plt.scatter(consulta3['Cant_EE'], consulta3['Cant_BP'], color=color_daltonico_friendly[4], s=20, alpha=0.7)
plt.xlabel('Cantidad de Establecimientos Educativos')
plt.ylabel('Cantidad de Bibliotecas Populares')
plt.title('Cant (TOTAl) de EE y Cant (TOTAL) de BP por Depto')
plt.grid(True)
plt.show()

### ----------------- Visualización 3

escuelas_por_depto = duckdb.sql("""
    SELECT
        e.id_departamento,
        COUNT(*) AS cantidad_escuelas
    FROM df_Escuela AS e
    GROUP BY id_departamento
""").df()
departamentos = duckdb.sql("""
    SELECT  d.id_departamento
        ,p.nombre AS Provincia
        ,d.nombre AS Departamento
        FROM df_Departamento AS d
        INNER JOIN df_Provincia AS p
        ON p.id_provincia == d.id_provincia
    """).df()
escuelas_con_provincia = pd.merge(escuelas_por_depto, departamentos, on='id_departamento')
orden_provincias = (
    escuelas_con_provincia
    .groupby("Provincia")["cantidad_escuelas"]
    .median()
    .sort_values()
    .index
)

# Departamentos más habitados por provincia
ordenado_por_poblacionDepto = duckdb.sql("""SELECT Provincia, Departamento, Población
                                            FROM consulta3
                                            GROUP BY Provincia, Departamento, Población
                                            ORDER BY Población desc""").df()
filtrado = ordenado_por_poblacionDepto[ordenado_por_poblacionDepto['Departamento'] != 'CABA (total)']
top3_por_provincia = (
    filtrado
    .groupby('Provincia', group_keys=False)
    .head(3)
)
tabla_final = (
    top3_por_provincia
    .groupby('Provincia')['Departamento']
    .apply(list)
    .reset_index()
)

##grafico (IV)
plt.figure(figsize=(15, 6))
sns.boxplot(
    data=escuelas_con_provincia,
    x="Provincia",
    y="cantidad_escuelas",
    order=orden_provincias, color = color_daltonico_friendly[2]
)
plt.xticks(rotation=45)
plt.title("Distribución de cantidad de escuelas por departamento en cada provincia")
plt.xlabel("Provincia")
plt.ylabel("Cantidad de escuelas por departamento")
plt.tight_layout()
plt.show()

### ----------------- visualización 4: Relación entre la cantidad de BP y de EE habitantes por departamento.


visualización4 = duckdb.sql("""
    WITH poblacion_total AS (
        SELECT id_departamento, SUM(cantidad) AS Poblacion_total
        FROM df_Poblacion_Depto
        GROUP BY id_departamento
    ),
    bp_por_depto AS (
        SELECT id_departamento, COUNT(*) AS cantidad_bp
        FROM df_Biblioteca_Popular
        GROUP BY id_departamento
    ),
    ee_por_depto AS (
        SELECT id_departamento, COUNT(*) AS cantidad_ee
        FROM df_Escuela
        GROUP BY id_departamento
    )

    SELECT
        p.id_departamento,
        p.poblacion_total,
        COALESCE(bp.cantidad_bp, 0) AS cantidad_bp,
        COALESCE(ee.cantidad_ee, 0) AS cantidad_ee,
        ROUND(1000.0 * COALESCE(bp.cantidad_bp, 0) / p.poblacion_total, 2) AS bp_por_mil,
        ROUND(1000.0 * COALESCE(ee.cantidad_ee, 0) / p.poblacion_total, 2) AS ee_por_mil
    FROM poblacion_total p
    LEFT JOIN bp_por_depto bp ON p.id_departamento = bp.id_departamento
    LEFT JOIN ee_por_depto ee ON p.id_departamento = ee.id_departamento
""").df()


plt.figure(figsize=(10, 6))
sns.scatterplot(data=visualización4, x="bp_por_mil", y="ee_por_mil")

plt.title("Relación entre Bibliotecas Populares y Establecimientos Educativos cada mil habitantes por departamento")
plt.xlabel("Bibliotecas Populares cada 1000 habitantes")
plt.ylabel("Establecimientos Educativos cada 1000 habitantes")
plt.grid(True)
plt.tight_layout()
plt.show()

## Buble plot
plt.figure(figsize=(10, 6))
sns.scatterplot(data=visualización4, x="bp_por_mil", y="ee_por_mil",
                size="Poblacion_total", sizes=(20, 250), hue="Poblacion_total", palette="viridis")

plt.title("Relación entre BP y EE por cada mil habitantes (tamaño de los puntos según población del respectivo departamento)")
plt.xlabel("Bibliotecas Populares cada 1000 habitantes")
plt.ylabel("Escuelas comunes cada 1000 habitantes")
plt.grid(True)
plt.tight_layout()
plt.show()

##aca hay un codigo para encontrar los puntos muy por fuera de la normal en el grafico
# Merge con Departamento para obtener nombre del departamento y su id_provincia
visualización4 = visualización4.merge(
    df_Departamento[['id_departamento', 'nombre', 'id_provincia']],
    on='id_departamento',
    how='left'
).rename(columns={'nombre': 'nombre_depto'})
# Luego merge con Provincia para obtener el nombre de la provincia
visualización4 = visualización4.merge(
    df_Provincia[['id_provincia', 'nombre']],
    on='id_provincia',
    how='left'
).rename(columns={'nombre': 'nombre_prov'})
# Coordenadas aproximadas de los puntos
puntos_interes = [
    (0.0, 13.0),
    (0.3, 13.0),
    (0.3, 10.9),
    (0.0, 10.8),
    (1.3, 5.0),
    (1.4, 8.4),
    (2.4, 7.0)
]
# Umbral para considerar un punto "cercano"
umbral = 0.1

# Buscar departamentos cercanos
for x0, y0 in puntos_interes:
    print(f"\n--- Cerca de (BP: {x0}, EE: {y0}) ---")
    cercanos = visualización4[
        ((visualización4['bp_por_mil'] - x0).abs() < umbral) &
        ((visualización4['ee_por_mil'] - y0).abs() < umbral)
    ]
    if not cercanos.empty:
        print(cercanos[['nombre_depto', 'nombre_prov', 'bp_por_mil', 'ee_por_mil', 'Poblacion_total']].to_string(index=False))
    else:
        print("No se encontraron departamentos cerca de este punto.")